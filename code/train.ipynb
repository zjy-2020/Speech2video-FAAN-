{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv2') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('ConvT') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)   \n",
    "    elif classname.find('BatchNorm2') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator().to(device)\n",
    "G.apply(weights_init)\n",
    "D_img = Discriminator_img().to(device)\n",
    "D_img.apply(weights_init)\n",
    "D_seq = Discriminator_seq().to(device)\n",
    "D_seq.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "G_optimizer = torch.optim.Adam(G.parameters(),lr=0.00004,betas=(beta1, 0.999))\n",
    "D_img_optimizer = torch.optim.Adam(D_img.parameters(),lr=0.000025,betas=(beta1, 0.999))\n",
    "D_seq_optimizer = torch.optim.Adam(D_seq.parameters(),lr=0.000025,betas=(beta1, 0.999))\n",
    "loss_fn = nn.MSELoss()\n",
    "loss1 = nn.L1Loss()\n",
    "def reset_grad():\n",
    "    D_img_optimizer.zero_grad()\n",
    "    G_optimizer.zero_grad()\n",
    "    D_seq_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "total_step = len(my_wavloader)\n",
    "G_losses = []\n",
    "D_img_losses = []\n",
    "D_step = 1\n",
    "G_step = 1\n",
    "for epoch in range(num_epochs):\n",
    "    for index,(wav_data,imgG_data,img_data) in enumerate(zip(my_wavloader,my_imgGloader,my_imgloader)):\n",
    "        \n",
    "        waveform,_ = wav_data\n",
    "        batch_size = img_data.shape[0]\n",
    "        waveform = waveform.to(device)\n",
    "        imgG_data = imgG_data.to(device)\n",
    "        img_data = img_data.to(device)\n",
    "        \n",
    "        real_labels = Variable(torch.ones(batch_size)).to(device)\n",
    "        fake_labels = Variable(torch.zeros(batch_size)).to(device)\n",
    "        for _ in range(1):\n",
    "            '''train d_img'''\n",
    "            outputs = D_img(img_data,imgG_data).view(-1)\n",
    "            #print(outputs.shape)\n",
    "            d_img_loss_real = loss_fn(outputs, real_labels)\n",
    "            d_img_loss_real = torch.mean((outputs - 1)**2)\n",
    "            d_loss_real = -torch.mean(outputs)\n",
    "            d_img_real_score = outputs\n",
    "            fake_images = G(imgG_data,waveform)\n",
    "            outputs = D_img(fake_images,imgG_data).view(-1)\n",
    "            d_img_loss_fake = loss_fn(outputs, fake_labels)\n",
    "            d_loss_fake= torch.mean(outputs)\n",
    "            d_img_loss_fake = torch.mean(outputs**2)\n",
    "            d_img_fake_score = outputs\n",
    "            D_img_optimizer.zero_grad()\n",
    "\n",
    "            d_img_loss=0.5*(d_img_loss_real+d_img_loss_fake)\n",
    "            d_img_loss= d_img_loss_real + d_img_loss_fake\n",
    "            d_img_loss.backward(retain_graph=True)\n",
    "            D_img_optimizer.step()\n",
    "            '''train d_seq'''\n",
    "            outputs = D_seq(img_data,waveform).view(-1)\n",
    "            d_seq_loss_real = loss_fn(outputs, real_labels)\n",
    "            d_seq_real_score = outputs\n",
    "            outputs = D_seq(fake_images,waveform).view(-1)\n",
    "            d_seq_loss_fake = loss_fn(outputs, fake_labels)\n",
    "            d_seq_fake_score = outputs\n",
    "            D_seq_optimizer.zero_grad()\n",
    "            d_seq_loss = d_seq_loss_real + d_seq_loss_fake\n",
    "            d_seq_loss.backward()\n",
    "            D_seq_optimizer.step()\n",
    "\n",
    "        for _ in range(1):\n",
    "            z = Variable(torch.randn(batch_size,10)).to(device)\n",
    "            fake_images = G(imgG_data,waveform)\n",
    "            outputs = D_img(fake_images,imgG_data).view(-1)\n",
    "            outputs_seq = D_seq(fake_images,waveform).view(-1)\n",
    "            \n",
    "            abs_lower_face = torch.split(torch.abs(fake_images-img_data), 100, 2)\n",
    "            g_loss = loss_fn(outputs, real_labels) + 400.*torch.mean(abs_lower_face[1])+ loss_fn(outputs_seq, real_labels)\n",
    "            g_loss = loss_fn(outputs, real_labels) + loss_fn(outputs_seq, real_labels)\n",
    "            g_loss = 0.5 * torch.mean((outputs - 1)**2)  + 400*loss1(fake_images,img_data) + 0.5 * torch.mean((outputs_seq - 1)**2) \n",
    "            G_optimizer.zero_grad()\n",
    "            g_loss.backward()\n",
    "            G_optimizer.step()\n",
    "\n",
    "        if index % 50 == 0:\n",
    "            print(\"Epoch [{}/{}], Step [{}/{}], d_img_loss: {:.4f},d_seq_loss: {:.4f}, g_loss: {:.4f}, D_img(x): {:.2f}, D_img(G(z)): {:.2f},D_seq(x): {:.2f}, D_seq(G(z)): {:.2f}\"\n",
    "                    .format(epoch, num_epochs, index, total_step, d_img_loss.item(), d_seq_loss.item(),g_loss.item(), d_img_real_score.mean().item(), d_img_fake_score.mean().item(),d_seq_real_score.mean().item(), d_seq_fake_score.mean().item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
