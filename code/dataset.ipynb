{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "class Wav_Dataset(Dataset):\n",
    "    def __init__(self,root):\n",
    "        '''root   transform_state  transform  '''\n",
    "        self.wav_files = [x.path for x in os.scandir(root) if x.name.endswith(\".wav\")]\n",
    "        self.wav_files.sort(key = lambda x : int(x.replace(root+\"...\",\"\").split('.')[0]))\n",
    "        self.wav_files = np.array(self.wav_files)\n",
    "        #print(self.wav_files)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #waveform  sample_rate  \n",
    "        waveform, sample_rate = torchaudio.load_wav(self.wav_files[index])\n",
    "        #waveform = torch.unsqueeze(waveform,1)\n",
    "        #print(waveform.shape)\n",
    "        tensor_minusmean = waveform - (waveform *1.0).mean()\n",
    "        waveform = tensor_minusmean/tensor_minusmean.abs().max()\n",
    "        # Spectorgarm = transforms.Spectrogram()(waveform)   \n",
    "        #if waveform.shape[1]<64000:\n",
    "        #waveform = waveform.permute(1,0)\n",
    "        #print(waveform.shape)\n",
    "        return waveform,sample_rate\n",
    "    def __len__(self):\n",
    "        return len(self.wav_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wav_test(Dataset):\n",
    "    def __init__(self,root):\n",
    "        '''root transform_state  transform  '''\n",
    "        self.wav_files = [x.path for x in os.scandir(root) if x.name.endswith(\".wav\")]\n",
    "        self.wav_files.sort(key = lambda x : int(x.replace(root,\"\").split('.')[0]))\n",
    "        self.wav_files = np.array(self.wav_files)\n",
    "        #print(self.wav_files[:10])\n",
    "      \n",
    "    def __getitem__(self, index):\n",
    "        waveform, sample_rate = torchaudio.load(self.wav_files[index])\n",
    "        #tensor_minusmean = waveform - waveform.mean()\n",
    "        #waveform = tensor_minusmean/tensor_minusmean.abs().max()\n",
    "        #Spectorgarm = transforms.Spectrogram()(waveform) \n",
    "        #if waveform.shape[1]<64000:\n",
    "        #waveform = waveform.permute(1,0)\n",
    "        return waveform,sample_rate\n",
    "    def __len__(self):\n",
    "        return len(self.wav_files)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_data_path = '/...../'\n",
    "#读取音频数据\n",
    "my_wavdataset = Wav_Dataset(wav_data_path)\n",
    "my_wavloader = DataLoader(my_wavdataset,batch_size=BATCH_SIZE,num_workers=0,shuffle=False)\n",
    "\n",
    "test_data = Wav_test('/..../')\n",
    "test_dataloader = DataLoader(test_data,batch_size=BATCH_SIZE,num_workers=0,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class My_Img_Dataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.image_files = [x.path for x in os.scandir(root) if x.name.endswith(\".jpg\") or x.name.endswith(\".png\") or x.name.endswith(\".JPG\")]\n",
    "        self.image_files.sort(key = lambda x : int(x.replace(root +'...','').split('.')[0]))\n",
    "        self.image_files = np.array(self.image_files)\n",
    "        #print(self.image_files[:10])\n",
    "        self.transform= transform\n",
    "    def __getitem__(self, index):\n",
    "        if self.transform:\n",
    "            image = Image.open(self.image_files[index]).convert('RGB')\n",
    "            image = self.transform(image)  \n",
    "            return image\n",
    "        else:\n",
    "            return Image.open(self.image_files[index]).convert('RGB')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Img_G_Dataset(Dataset):\n",
    "    def __init__(self, root,batch_size,audio_len,transform=None):\n",
    "        self.batch_size = batch_size+1\n",
    "        self.image_files = [x.path for x in os.scandir(root) if x.name.endswith(\".jpg\") or x.name.endswith(\".png\") or x.name.endswith(\".JPG\")]\n",
    "        self.image_files.sort(key = lambda x : int(x.replace(root+\"....\",'').split('.')[0]))\n",
    "        self.audio_len = audio_len\n",
    "        self.image_files = [self.image_files[i] for i in range(0,len(self.image_files),self.batch_size)]\n",
    "        self.image_files_gj = []\n",
    "        if len(self.image_files) == 1:\n",
    "            x = self.image_files[0]\n",
    "            for k in range(audio_len):\n",
    "                self.image_files_gj.append(x)\n",
    "        else:  \n",
    "            for i in range(1,len(self.image_files)):\n",
    "                x = self.image_files[i]\n",
    "                for k in range(batch_size):\n",
    "                    self.image_files_gj.append(x)\n",
    "        self.image_files = self.image_files_gj\n",
    "        self.image_files = np.array(self.image_files)\n",
    "        #print(self.image_files[:10])\n",
    "        self.transform= transform\n",
    "    def __getitem__(self, index):\n",
    "        if self.transform:\n",
    "            image = Image.open(self.image_files[index]).convert('RGB')\n",
    "            image = self.transform(image)  \n",
    "            #print(image.shape)\n",
    "            return image\n",
    "        else:\n",
    "            return Image.open(self.image_files[index]).convert('RGB')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((200,200)),\n",
    "    torchvision.transforms.CenterCrop(200),\n",
    "    torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5])\n",
    "                                           ])\n",
    "\n",
    "transform1 = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((200,200)),\n",
    "    torchvision.transforms.CenterCrop(200),\n",
    "    torchvision.transforms.ToTensor(),  \n",
    "    torchvision.transforms.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5])  \n",
    "])\n",
    "#img_data_path = '/.../'\n",
    "img_data_path = '/.../'\n",
    "img_D_path = '/.../'\n",
    "#img_D_path = '/.../'\n",
    "my_imgdataset = My_Img_Dataset(img_D_path,transform)\n",
    "my_imgloader = DataLoader(my_imgdataset,batch_size=BATCH_SIZE,num_workers=0,shuffle=False)\n",
    "\n",
    "my_imgGdataset = My_Img_G_Dataset('/../',BATCH_SIZE,len(my_wavdataset),transform)\n",
    "my_imgGloader = DataLoader(my_imgGdataset,batch_size=BATCH_SIZE,num_workers=0,shuffle=False)\n",
    "my_imgG1dataset = My_Img_G_Dataset('/.../',BATCH_SIZE,len(test_data),transform1)\n",
    "my_imgG1loader = DataLoader(my_imgG1dataset,batch_size=BATCH_SIZE,num_workers=0,shuffle=False)\n",
    "#print(my_imgG1loader)\n",
    "#q = np.array(my_imgG1loader)\n",
    "#print(q.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
